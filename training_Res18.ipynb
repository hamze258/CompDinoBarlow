{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Resnet 18 for Barlow Twins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99540a6",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Libraries ---\n",
    "import os\n",
    "import time\n",
    "import h5py  # For reading and writing HDF5 files\n",
    "import numpy as np\n",
    "from glob import iglob  # For finding files with glob patterns\n",
    "from PIL import Image  # For image manipulation\n",
    "from tqdm import tqdm, trange  # For progress bars\n",
    "\n",
    "# --- PyTorch Core Libraries ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn  # For CUDA optimizations\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter  # For logging to TensorBoard\n",
    "from torch.cuda.amp import GradScaler, autocast  # For mixed-precision training\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.checkpoint import checkpoint  # For gradient checkpointing\n",
    "\n",
    "# --- Additional Libraries ---\n",
    "import torch_optimizer as optim_extra  # For extra optimizers like LARS\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "# Print the PyTorch version to verify the environment setup\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9969557",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4e1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Choose one of the following configurations by uncommenting the desired block.\n",
    "\n",
    "# --- Option 1: Prepare dataset ---\n",
    "# mode = \"prepare\"\n",
    "# root_dir = \"data/s2_rgb/0k_251k_uint8_jpeg_tif/rgb\"\n",
    "# h5_path = \"data/s2_rgb/augmented_dataset_100000_res18.h5\"\n",
    "# logdir = \"runs/barlow_twins_ssl4eo_rgb_100000_res18\"\n",
    "# max_samples = 100000\n",
    "# epochs = 100\n",
    "\n",
    "# --- Option 2: Train on dataset (CURRENTLY ACTIVE) ---\n",
    "mode = \"train\"\n",
    "root_dir = \"data/s2_rgb/0k_251k_uint8_jpeg_tif/rgb\" # Directory containing the dataset\n",
    "h5_path = \"data/s2_rgb/augmented_dataset_100000_res18.h5\" # Path to the HDF5 file containing the dataset\n",
    "logdir = \"runs/barlow_twins_ssl4eo_rgb_100000_res18\" # Directory for TensorBoard logs\n",
    "max_samples = 100000\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282949c",
   "metadata": {},
   "source": [
    "## 3. Dataset Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3de8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiffRGBDataset(Dataset):\n",
    "    \"\"\"A PyTorch Dataset for loading TIFF images and converting them to RGB.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, max_samples=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): The root directory containing the TIFF images.\n",
    "            max_samples (int, optional): Maximum number of samples to load. Defaults to None (load all).\n",
    "            transform (callable, optional): A function/transform to apply to the images. Defaults to None.\n",
    "        \"\"\"\n",
    "        # Expand user path (e.g., '~') and store the transform\n",
    "        root_dir = os.path.expanduser(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Create a pattern to find all .tif/.TIF files recursively\n",
    "        pattern = os.path.join(root_dir, '**', '*.[tT][iI][fF]')\n",
    "\n",
    "        # Find all samples, sort them, and optionally limit the number of samples\n",
    "        all_samples = sorted(iglob(pattern, recursive=True))\n",
    "        self.samples = all_samples[:max_samples] if max_samples else all_samples\n",
    "\n",
    "        print(f\"[DEBUG] Found {len(all_samples)} total images. Loading {len(self.samples)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Fetches the image at the given index, converts it to RGB, and applies the transform.\"\"\"\n",
    "        # Open the image file, ensure it is in RGB format\n",
    "        img = Image.open(self.samples[idx]).convert('RGB')\n",
    "\n",
    "        # Apply the transform if it is provided\n",
    "        if self.transform:\n",
    "            return self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e81cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HDF5 Dataset ---\n",
    "class HDF5Dataset(Dataset):\n",
    "    \"\"\"A PyTorch Dataset for loading data from an HDF5 file.\"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.f = h5py.File(path, \"r\")\n",
    "        self.v1, self.v2 = self.f[\"view1\"], self.f[\"view2\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.v1.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image pair and normalize to [0, 1]\n",
    "        i1 = torch.from_numpy(self.v1[idx].astype(np.float32) / 255.)\n",
    "        i2 = torch.from_numpy(self.v2[idx].astype(np.float32) / 255.)\n",
    "        return i1, i2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2483c96",
   "metadata": {},
   "source": [
    "## 4. Data Preparation & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9347cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell calculates the mean and standard deviation of the dataset.\n",
    "# These statistics are useful for normalization.\n",
    "\n",
    "# Define a simple transformation to resize images and convert them to a tensor\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),  # Ensure all images have the same size\n",
    "    T.ToTensor(),           # Convert PIL Image to a PyTorch tensor\n",
    "]) \n",
    "\n",
    "# Initialize the dataset with a large number of samples for accurate statistics\n",
    "dataset = TiffRGBDataset(\n",
    "    root_dir=\"data/s2_rgb/0k_251k_uint8_jpeg_tif/rgb\",\n",
    "    max_samples=100000,  # Using 100k images for calculation\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create a DataLoader to iterate over the dataset in batches\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,  # No need to shuffle for calculating statistics\n",
    "    num_workers=0,  # Set to 0 for this calculation to avoid multi-processing issues\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Initialize tensors to accumulate the sum and sum of squares of pixel values\n",
    "sum_ = torch.zeros(3)    # Sum of pixel values for each of the 3 (RGB) channels\n",
    "sum_sq = torch.zeros(3)  # Sum of squared pixel values for each channel\n",
    "num_pixels = 0           # Total number of pixels processed\n",
    "\n",
    "# Iterate through the dataset with a progress bar\n",
    "for batch in tqdm(loader, desc=\"Computing mean and std\"):\n",
    "    # Ensure the batch is in float32 for precise calculations\n",
    "    batch = batch.to(torch.float32)\n",
    "    b, c, h, w = batch.shape  # Batch size, channels, height, width\n",
    "\n",
    "    # Update accumulators\n",
    "    sum_ += batch.sum(dim=[0, 2, 3])         # Sum pixel values across batch, height, and width\n",
    "    sum_sq += (batch ** 2).sum(dim=[0, 2, 3])  # Sum squared pixel values\n",
    "    num_pixels += b * h * w                    # Increment the total pixel count\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "mean = sum_ / num_pixels\n",
    "std = torch.sqrt(sum_sq / num_pixels - mean ** 2)\n",
    "\n",
    "# Print the final results\n",
    "print(f\"Computed Mean: {mean.tolist()}\")\n",
    "print(f\"Computed Std:  {std.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f71e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines the data augmentations for Barlow Twins.\n",
    "\n",
    "# --- Augmentation Setup ---\n",
    "# The following mean and std values were pre-calculated on a 100k image subset.\n",
    "mean_list = [0.4824, 0.4808, 0.4779]\n",
    "std_list  = [0.1902, 0.1688, 0.1462]\n",
    "\n",
    "# Convert lists to PyTorch tensors\n",
    "mean = torch.tensor(mean_list, dtype=torch.float32)\n",
    "std  = torch.tensor(std_list,  dtype=torch.float32)\n",
    "\n",
    "# Define the base set of transformations applied to both views\n",
    "base_transforms = [\n",
    "    T.RandomResizedCrop(224, scale=(0.08, 1.0), interpolation=InterpolationMode.BICUBIC),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomApply([T.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8, hue=0.2)], p=0.8),\n",
    "    T.RandomGrayscale(p=0.2),\n",
    "    T.RandomApply([T.GaussianBlur(kernel_size=23)], p=0.5), # kernel_size must be odd\n",
    "]\n",
    "\n",
    "# Create the first transformation pipeline\n",
    "transform_1 = T.Compose(base_transforms + [\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# Create the second transformation pipeline, adding RandomSolarize\n",
    "transform_2 = T.Compose(base_transforms + [\n",
    "    T.RandomSolarize(threshold=0.5, p=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "# --- Two-Crop Transform for Barlow Twins ---\n",
    "class TwoCropTransformBT:\n",
    "    \"\"\"A transform that creates two different augmented views of the same image.\"\"\"\n",
    "    def __init__(self, t1, t2):\n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"Applies the two transforms and returns a pair of augmented images.\"\"\"\n",
    "        return self.t1(img), self.t2(img)\n",
    "\n",
    "# --- Visualization Function ---\n",
    "def log_augment_steps(img: Image.Image, writer: SummaryWriter, base_transforms: list, step: int = 0):\n",
    "    \"\"\"Logs the result of each base augmentation step to TensorBoard.\"\"\"\n",
    "    # Define the operations with descriptive names\n",
    "    ops = [\n",
    "        (\"01_ResizeCrop\", base_transforms[0]),\n",
    "        (\"02_HFlip\", base_transforms[1]),\n",
    "        (\"03_ColorJitter\", base_transforms[2].transforms[0] if isinstance(base_transforms[2], T.RandomApply) else base_transforms[2]),\n",
    "        (\"04_Gray\", base_transforms[3]),\n",
    "        (\"05_GaussianBlur\", base_transforms[4].transforms[0] if isinstance(base_transforms[4], T.RandomApply) else base_transforms[4]),\n",
    "    ]\n",
    "\n",
    "    x = img\n",
    "    # Apply each operation sequentially and log the result\n",
    "    for name, op in ops:\n",
    "        x = op(x)\n",
    "        # Convert the image to a tensor to be logged\n",
    "        t = T.ToTensor()(x)\n",
    "        writer.add_image(f\"Augment/{name}\", torchvision.utils.make_grid(t.unsqueeze(0), normalize=True), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29270420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_h5(root_dir, out_path, max_samples, log_dir):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by applying augmentations and saving the results\n",
    "    into an HDF5 file for faster loading during training.\n",
    "    \"\"\"\n",
    "    # Create a SummaryWriter for TensorBoard logging\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir, \"prep\"))\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "    # Initialize the dataset with the two-crop transform\n",
    "    dataset = TiffRGBDataset(\n",
    "        root_dir=root_dir,\n",
    "        transform=TwoCropTransformBT(transform_1, transform_2),\n",
    "        max_samples=max_samples\n",
    "    )\n",
    "\n",
    "    # Log dataset information to TensorBoard\n",
    "    writer.add_text(\"Dataset/Info\",\n",
    "                    f\"Root: {root_dir}\\nSamples: {len(dataset)}\\nTransforms: {base_transforms}\",\n",
    "                    global_step=0)\n",
    "\n",
    "    # Log an original sample image for reference\n",
    "    sample_orig = Image.open(dataset.samples[min(1, len(dataset)-1)]).convert(\"RGB\")\n",
    "    orig_t = T.ToTensor()(sample_orig)\n",
    "    writer.add_image(\"Dataset/OriginalSample\",\n",
    "                     torchvision.utils.make_grid(orig_t.unsqueeze(0), normalize=True),\n",
    "                     global_step=0)\n",
    "\n",
    "    # Log the augmentation steps for visualization\n",
    "    log_augment_steps(sample_orig, writer, base_transforms, step=0)\n",
    "\n",
    "    # Log a histogram of the crop scales to understand the distribution\n",
    "    scales = []\n",
    "    for _ in range(100):\n",
    "        _, _, h, _ = T.RandomResizedCrop.get_params(sample_orig, scale=(0.8, 1.0), ratio=(1, 1))\n",
    "        scales.append(h / 224)\n",
    "    writer.add_histogram(\"Augment/ScaleDist\", torch.tensor(scales), global_step=0)\n",
    "\n",
    "    # --- Write to HDF5 file ---\n",
    "    N = len(dataset)\n",
    "    with h5py.File(out_path, \"w\") as f:\n",
    "        # Create datasets for the two augmented views\n",
    "        d1 = f.create_dataset(\"view1\", (N, 3, 224, 224), dtype=\"uint8\")\n",
    "        d2 = f.create_dataset(\"view2\", (N, 3, 224, 224), dtype=\"uint8\")\n",
    "\n",
    "        # Iterate through the dataset and save the augmented views\n",
    "        for i in trange(N, desc=\"Writing to HDF5\"):\n",
    "            x1, x2 = dataset[i]\n",
    "            # Scale to [0, 255] and save as byte to save space\n",
    "            d1[i] = (x1.mul(255).byte().numpy())\n",
    "            d2[i] = (x2.mul(255).byte().numpy())\n",
    "\n",
    "    writer.close()\n",
    "    print(f\"HDF5 file saved to: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc3b8a",
   "metadata": {},
   "source": [
    "## 5. Model and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33100c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Barlow Twins Model ---\n",
    "class BarlowTwinsModel(nn.Module):\n",
    "    \"\"\"The Barlow Twins model architecture.\"\"\"\n",
    "    def __init__(self, proj_dim=2048, hidden_dim=8192):\n",
    "        super().__init__()\n",
    "        # 1) Backbone: Pretrained ResNet-18\n",
    "        self.backbone = resnet18(pretrained=True)\n",
    "        feat_dim = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()  # Remove the final classification layer\n",
    "\n",
    "        # 2) Projector: A 3-layer MLP\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(feat_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, hidden_dim, bias=False),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, proj_dim, bias=False),\n",
    "            nn.BatchNorm1d(proj_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"Passes both augmented views through the backbone and projector.\"\"\"\n",
    "        z1 = self.projector(self.backbone(x1))\n",
    "        z2 = self.projector(self.backbone(x2))\n",
    "        return z1, z2\n",
    "\n",
    "# --- Loss Function ---\n",
    "def off_diagonal(x):\n",
    "    \"\"\"Returns the off-diagonal elements of a matrix.\"\"\"\n",
    "    n, _ = x.shape\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "def barlow_twins_loss(z1, z2, lambda_offdiag=5e-3):\n",
    "    \"\"\"Calculates the Barlow Twins loss.\"\"\"\n",
    "    B, D = z1.size()  # Batch size, Dimensionality\n",
    "\n",
    "    # 1) Normalize the representations\n",
    "    z1_norm = (z1 - z1.mean(0)) / z1.std(0)\n",
    "    z2_norm = (z2 - z2.mean(0)) / z2.std(0)\n",
    "\n",
    "    # 2) Compute the cross-correlation matrix\n",
    "    C = (z1_norm.T @ z2_norm) / B\n",
    "\n",
    "    # 3) Calculate the loss\n",
    "    on_diag = torch.diagonal(C)\n",
    "    invariance_loss = ((on_diag - 1)**2).sum()\n",
    "    redundancy_loss = (off_diagonal(C)**2).sum()\n",
    "    return invariance_loss + lambda_offdiag * redundancy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562ef9a6",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training Function ---\n",
    "def train(h5_path, log_dir, total_epochs=100, batch_size=32, accum_steps=4, lr=5e-5):\n",
    "    \"\"\"The main training loop.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load the HDF5 dataset\n",
    "    ds = HDF5Dataset(h5_path)\n",
    "    print(f\"Number of samples in dataset: {len(ds)}\")\n",
    "\n",
    "    # Create the DataLoader\n",
    "    loader = DataLoader(ds, batch_size=batch_size, shuffle=True,\n",
    "                        num_workers=8, pin_memory=True,\n",
    "                        persistent_workers=True, prefetch_factor=2, drop_last=True)\n",
    "\n",
    "    if len(loader) == 0:\n",
    "        print(\"DataLoader is empty. Cannot proceed with training.\")\n",
    "        return\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    model = BarlowTwinsModel().to(device)\n",
    "\n",
    "    # LARS Optimizer\n",
    "    optimizer = optim_extra.LARS(\n",
    "        model.parameters(),\n",
    "        lr=lr,  # Base LR is scaled by batch_size / 256 in the paper\n",
    "        weight_decay=1e-6,\n",
    "        momentum=0.9,\n",
    "    )\n",
    "\n",
    "    # Learning rate scheduler with warmup\n",
    "    warmup_epochs = 10\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        optimizer,\n",
    "        schedulers=[\n",
    "            LinearLR(optimizer, start_factor=0.01, total_iters=warmup_epochs),\n",
    "            CosineAnnealingLR(optimizer, T_max=total_epochs - warmup_epochs)\n",
    "        ],\n",
    "        milestones=[warmup_epochs]\n",
    "    )\n",
    "\n",
    "    # GradScaler for mixed-precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    writer = SummaryWriter(log_dir=os.path.join(log_dir, \"train\"))\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    ckpt_dir = os.path.join(log_dir, \"checkpoints\")\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "    # --- Training Loop ---\n",
    "    for epoch in range(total_epochs):\n",
    "        start_time = time.time()\n",
    "        loss_accumulator = 0\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (x1, x2) in enumerate(loader):\n",
    "            x1, x2 = x1.to(device), x2.to(device)\n",
    "\n",
    "            # Forward pass with automatic mixed precision\n",
    "            with torch.amp.autocast():\n",
    "                z1, z2 = model(x1, x2)\n",
    "                loss = barlow_twins_loss(z1, z2) / accum_steps\n",
    "\n",
    "            # Backward pass\n",
    "            scaler.scale(loss).backward()\n",
    "            loss_accumulator += loss.item() * accum_steps\n",
    "\n",
    "            # Gradient accumulation\n",
    "            if (batch_idx + 1) % accum_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Log batch-level stats\n",
    "            step = epoch * len(loader) + batch_idx\n",
    "            writer.add_scalar(\"Loss/train_batch\", loss.item() * accum_steps, step)\n",
    "            writer.add_scalar(\"LR\", optimizer.param_groups[0]['lr'], step)\n",
    "\n",
    "        # --- End of Epoch ---\n",
    "        scheduler.step()\n",
    "        epoch_loss = loss_accumulator / len(loader) if len(loader) > 0 else 0\n",
    "        writer.add_scalar(\"Loss/train_epoch\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Time/epoch\", time.time() - start_time, epoch)\n",
    "        print(f\"Epoch {epoch+1}/{total_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 10 == 0 or (epoch + 1) == total_epochs:\n",
    "            ckpt_path = os.path.join(ckpt_dir, f\"barlow_epoch_{epoch+1:03d}.pt\")\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "            }, ckpt_path)\n",
    "            print(f\"[CHECKPOINT] Saved to {ckpt_path}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ffd7c",
   "metadata": {},
   "source": [
    "## 7. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fe5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execution ---\n",
    "# This cell runs the appropriate function based on the 'mode' variable\n",
    "# defined in the configuration cells above.\n",
    "\n",
    "if mode == \"prepare\":\n",
    "    # If in 'prepare' mode, run the HDF5 creation process\n",
    "    prepare_h5(root_dir, h5_path, max_samples, logdir)\n",
    "elif mode == \"train\":\n",
    "    # If in 'train' mode, start the training process\n",
    "    train(h5_path, logdir, total_epochs=epochs)\n",
    "else:\n",
    "    # Raise an error for an unknown mode\n",
    "    raise ValueError(f\"Unknown mode: {mode}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
